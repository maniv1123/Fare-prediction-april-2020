{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any analysis is done, the taxi_clean_lg is imported. Ride_duration is added as a feature, and the pick up and drop off times are converted to a datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80501, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>winter</th>\n",
       "      <th>spring</th>\n",
       "      <th>summer</th>\n",
       "      <th>fall</th>\n",
       "      <th>PULongitude</th>\n",
       "      <th>PULatitude</th>\n",
       "      <th>DOLongitude</th>\n",
       "      <th>DOLatitude</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>ride_duration</th>\n",
       "      <th>Early morning</th>\n",
       "      <th>Morning</th>\n",
       "      <th>Afternoon</th>\n",
       "      <th>Night</th>\n",
       "      <th>Holiday Proximity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.984176</td>\n",
       "      <td>40.759845</td>\n",
       "      <td>-73.961815</td>\n",
       "      <td>40.809570</td>\n",
       "      <td>2019-03-26 14:24:29</td>\n",
       "      <td>2019-03-26 15:26:27</td>\n",
       "      <td>0 days 01:01:58.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.31</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.965572</td>\n",
       "      <td>40.782460</td>\n",
       "      <td>-73.853384</td>\n",
       "      <td>40.752316</td>\n",
       "      <td>2019-07-03 07:15:18</td>\n",
       "      <td>2019-07-03 07:49:08</td>\n",
       "      <td>0 days 00:33:50.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.99</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.981352</td>\n",
       "      <td>40.773906</td>\n",
       "      <td>-73.987973</td>\n",
       "      <td>40.775770</td>\n",
       "      <td>2019-05-25 17:25:49</td>\n",
       "      <td>2019-05-25 17:30:21</td>\n",
       "      <td>0 days 00:04:32.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.91</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.972145</td>\n",
       "      <td>40.756816</td>\n",
       "      <td>-73.956972</td>\n",
       "      <td>40.780491</td>\n",
       "      <td>2019-07-22 15:31:00</td>\n",
       "      <td>2019-07-22 15:41:36</td>\n",
       "      <td>0 days 00:10:36.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.18</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.965691</td>\n",
       "      <td>40.768542</td>\n",
       "      <td>-73.954568</td>\n",
       "      <td>40.765507</td>\n",
       "      <td>2019-03-13 21:13:28</td>\n",
       "      <td>2019-03-13 21:21:42</td>\n",
       "      <td>0 days 00:08:14.000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_distance  fare_amount  winter  spring  summer  fall  PULongitude  \\\n",
       "0           5.90         41.5       0       1       0     0   -73.984176   \n",
       "1           7.31         28.0       0       0       1     0   -73.965572   \n",
       "2           0.99          5.5       0       1       0     0   -73.981352   \n",
       "3           1.91          9.0       0       0       1     0   -73.972145   \n",
       "4           1.18          7.5       0       1       0     0   -73.965691   \n",
       "\n",
       "   PULatitude  DOLongitude  DOLatitude      pickup_datetime  \\\n",
       "0   40.759845   -73.961815   40.809570  2019-03-26 14:24:29   \n",
       "1   40.782460   -73.853384   40.752316  2019-07-03 07:15:18   \n",
       "2   40.773906   -73.987973   40.775770  2019-05-25 17:25:49   \n",
       "3   40.756816   -73.956972   40.780491  2019-07-22 15:31:00   \n",
       "4   40.768542   -73.954568   40.765507  2019-03-13 21:13:28   \n",
       "\n",
       "      dropoff_datetime              ride_duration  Early morning  Morning  \\\n",
       "0  2019-03-26 15:26:27  0 days 01:01:58.000000000              0        0   \n",
       "1  2019-07-03 07:49:08  0 days 00:33:50.000000000              0        1   \n",
       "2  2019-05-25 17:30:21  0 days 00:04:32.000000000              0        0   \n",
       "3  2019-07-22 15:41:36  0 days 00:10:36.000000000              0        0   \n",
       "4  2019-03-13 21:21:42  0 days 00:08:14.000000000              0        0   \n",
       "\n",
       "   Afternoon  Night  Holiday Proximity label  \n",
       "0          1      0                  1     J  \n",
       "1          0      0                  0     J  \n",
       "2          1      0                  0     B  \n",
       "3          1      0                  0     C  \n",
       "4          0      0                  0     C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import time\n",
    "\n",
    "#import data \n",
    "data = pd.read_csv(\"taxi_clean_lg.csv\")\n",
    "\n",
    "#display data\n",
    "print(data.shape)\n",
    "      \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'])\n",
    "data['pickup_datetime'] = pd.to_numeric(data['pickup_datetime'])\n",
    "data['dropoff_datetime'] = pd.to_datetime(data['dropoff_datetime'])\n",
    "data['dropoff_datetime'] = pd.to_numeric(data['dropoff_datetime'])\n",
    "\n",
    "data['ride_duration'] = data['dropoff_datetime'] - data['pickup_datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The necessary libraries needed for analysis are imported first. Feature values and class labels are defined next for KNN to use through a pipeline, in order to search for the best combination between PCA dimensions and n_neighbors. The pipeline was defined, created, and the parameters were set up to tune further for each step in the pipeline. The pipeline was then passed into GridSearchCV, and the best score and parameters were printed at the end of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score 0.7165376827617048\n",
      "best_params {'knn__n_neighbors': 5, 'pca__n_components': 12}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "featurevalues = data.drop(['label'], axis = 1)\n",
    "classlabels = data['label']\n",
    "\n",
    "# define a pipeline to search for best combination of PCA dimensions and n_neighbors\n",
    "scaler = MinMaxScaler()\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# create a pipeline\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('knn', knn)])\n",
    "\n",
    "# set up parameters to tune for each step in pipeline\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(1, 19)), # find how many principal componenet to keep\n",
    "    'knn__n_neighbors': list(range(1, 30)),  # find the best value of k\n",
    "}\n",
    "\n",
    "# pass pipeline into gridsearchcv\n",
    "grid_pipe = GridSearchCV(pipe,param_grid,cv=5)\n",
    "\n",
    "# call fit on grid_pipe and pass in unscaled data\n",
    "grid_pipe = grid_pipe.fit(featurevalues,classlabels)\n",
    "\n",
    "# print out the best_score_ and best_params_ from the GridSearchCV\n",
    "print(\"best_score\",grid_pipe.best_score_)\n",
    "print(\"best_params\",grid_pipe.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_val_score was used to determine the accuracy of the model, and the accuracy of the model was further reported through the use of classification report as well as the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=23.8min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 23.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=23.8min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=23.6min\n",
      "Accuracy: 71.28976539592934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 71.2min finished\n"
     ]
    }
   ],
   "source": [
    "# display accuracy on model\n",
    "scores = cross_val_score(grid_pipe,featurevalues,classlabels,cv=3,verbose=2)\n",
    "print(\"Accuracy:\", scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: [[ 798 2642 1428  572  228   65   34    8    3   93]\n",
      " [2294 8312 4988 2021  759  256  124   53   27  308]\n",
      " [1887 7066 4338 1911  733  266  132   47   16  272]\n",
      " [1212 4559 3010 1428  581  230  106   39   18  236]\n",
      " [ 724 2782 1874  975  444  176   81   42   19  185]\n",
      " [ 427 1640 1200  691  301  136   66   34   12  170]\n",
      " [ 261 1091  818  485  228   92   47   19   10  139]\n",
      " [ 172  711  588  346  144   65   38   25    6  139]\n",
      " [ 138  496  419  217  118   52   28   19   10  117]\n",
      " [ 521 2193 1917 1280  714  339  189   86   47 1098]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.09      0.14      0.11      5871\n",
      "           B       0.26      0.43      0.33     19142\n",
      "           C       0.21      0.26      0.23     16668\n",
      "           D       0.14      0.13      0.13     11419\n",
      "           E       0.10      0.06      0.08      7302\n",
      "           F       0.08      0.03      0.04      4677\n",
      "           G       0.06      0.01      0.02      3190\n",
      "           H       0.07      0.01      0.02      2234\n",
      "           I       0.06      0.01      0.01      1614\n",
      "           J       0.40      0.13      0.20      8384\n",
      "\n",
      "    accuracy                           0.21     80501\n",
      "   macro avg       0.15      0.12      0.12     80501\n",
      "weighted avg       0.19      0.21      0.19     80501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show results with classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "featurevalues = data.drop(['label'], axis = 1)\n",
    "classlabels = data['label']\n",
    "y_pred = cross_val_predict(knn,featurevalues,classlabels,cv=3)\n",
    "print(\"Confusion matrix:\",confusion_matrix(classlabels,y_pred))\n",
    "print(\"Classification Report:\",classification_report(classlabels,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1- score was greatest for class B, while the lowest was for class I. Additionally, based on the confusion matrix, a lot of data points in class I were misclassified to be in class J. It's also important to note that from the confusion matrix, many of the classes were misclassified to be in class B. For example, 2294 entries from class A were identified to be in class B, 7066 entries from class B were misidentified to be in class C (which is almost equal to those that were correctly classified to be in class B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The needed libraries were imported first, then the pipeline was set up. Using the default values, the accuracy of the pipelinew as found using cross_val_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.59635721561409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = StandardScaler()\n",
    "svc = SVC()\n",
    "\n",
    "# set up pipeline\n",
    "pipe = Pipeline(steps=[('scaler',scaler),('svc',svc)])\n",
    "pipeline = cross_val_score(pipe,featurevalues,classlabels,cv=5)\n",
    "print(\"Accuracy:\", pipeline.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel hyperparameter of the SVM pipeline was tuned further. Out of the parameters tested, the best parameter was found and printed. To further tune the model, the best value of c was tested and used to find the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__kernel': 'linear'}\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=15.1min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 15.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=15.3min\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=14.9min\n",
      "Accuracy: 99.99006221975525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 45.4min finished\n"
     ]
    }
   ],
   "source": [
    "# tune 'svm' part of the pipeline, 'kernel' hyperparameter\n",
    "param_grid = {'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# find and print best parameter\n",
    "gridsearch = GridSearchCV(pipe,param_grid,cv=3)\n",
    "gridsearch = gridsearch.fit(featurevalues,classlabels)\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "# find best value of c and print accuracy\n",
    "c = []\n",
    "for x in range(50,110,10):\n",
    "    c.append(x)\n",
    "param_grid = {'svc__kernel':['linear','rbf','poly','sigmoid'],'svc__C':c}\n",
    "grid_search = GridSearchCV(pipe,param_grid,cv=3)\n",
    "grid_accuracy = cross_val_score(grid_search,featurevalues,classlabels,cv=3,verbose=2)\n",
    "print(\"Accuracy:\",grid_accuracy.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: [[    0  5871     0     0     0     0     0     0     0     0]\n",
      " [    0 19142     0     0     0     0     0     0     0     0]\n",
      " [    0 16668     0     0     0     0     0     0     0     0]\n",
      " [    0 11419     0     0     0     0     0     0     0     0]\n",
      " [    0  7302     0     0     0     0     0     0     0     0]\n",
      " [    0  4677     0     0     0     0     0     0     0     0]\n",
      " [    0  3190     0     0     0     0     0     0     0     0]\n",
      " [    0  2234     0     0     0     0     0     0     0     0]\n",
      " [    0  1614     0     0     0     0     0     0     0     0]\n",
      " [    0  8382     0     0     0     0     0     0     0     2]]\n",
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.00      0.00      0.00      5871\n",
      "           B       0.24      1.00      0.38     19142\n",
      "           C       0.00      0.00      0.00     16668\n",
      "           D       0.00      0.00      0.00     11419\n",
      "           E       0.00      0.00      0.00      7302\n",
      "           F       0.00      0.00      0.00      4677\n",
      "           G       0.00      0.00      0.00      3190\n",
      "           H       0.00      0.00      0.00      2234\n",
      "           I       0.00      0.00      0.00      1614\n",
      "           J       1.00      0.00      0.00      8384\n",
      "\n",
      "    accuracy                           0.24     80501\n",
      "   macro avg       0.12      0.10      0.04     80501\n",
      "weighted avg       0.16      0.24      0.09     80501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show results with classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "featurevalues = data.drop(['label'], axis = 1)\n",
    "classlabels = data['label']\n",
    "y_pred = cross_val_predict(svc,featurevalues,classlabels,cv=3)\n",
    "print(\"Confusion matrix:\",confusion_matrix(classlabels,y_pred))\n",
    "print(\"Classification report:\",classification_report(classlabels,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy rate of the model is very high at 99.99%. However, by looking at the classification report, we see that a lot of entries are being classified as B (high recall), but are being misclassified (low precision). Additionally, entries in J are being misclassified. This may be because of class imbalance. Therefore, the accuracy being reported by cross_val_score is not true. Rather, it is significantly lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
